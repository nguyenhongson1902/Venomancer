{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.simple import NetC_MNIST\n",
    "\n",
    "classifier = NetC_MNIST(channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a crossentropy loss instance PyTorch\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intiliaze a tensor of size 100, 3, 32, 32 filled with -1 values\n",
    "data = torch.ones((100, 3, 32, 32)) * -1\n",
    "\n",
    "# Initialize a tensor of size 100 filled with random integers from 0 to 9\n",
    "target = torch.randint(0, 9, (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3, 32, 32]), torch.Size([100]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = classifier(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1300e-01,  7.4250e-02,  6.1700e-02,  5.5718e-02, -1.1506e-01,\n",
       "         -3.6060e-02, -8.5331e-02,  1.1605e-02,  2.1853e-01,  6.5895e-02],\n",
       "        [-3.1698e-02, -4.4403e-02,  5.7291e-02, -9.4476e-02,  2.0609e-02,\n",
       "          6.2469e-02,  8.5031e-03,  5.2436e-02,  2.3305e-01,  1.2373e-01],\n",
       "        [-5.8529e-02,  5.1005e-02,  9.7616e-02, -6.7404e-02,  1.1168e-02,\n",
       "          1.2670e-03, -7.3874e-02, -4.3440e-02,  1.8123e-01,  5.3787e-02],\n",
       "        [-2.7388e-02, -1.0760e-02,  6.5633e-02, -6.5326e-02, -5.0581e-02,\n",
       "         -5.4159e-03, -5.1744e-02,  8.5804e-02,  1.2904e-01,  4.3034e-02],\n",
       "        [-3.2934e-02, -6.4590e-02,  2.5096e-02, -1.1611e-01, -4.8705e-02,\n",
       "          3.4599e-03,  4.0598e-02,  7.2518e-02,  7.3025e-02,  9.3094e-02],\n",
       "        [-1.0579e-01,  5.0917e-02,  7.2105e-02, -3.6344e-03, -1.5186e-02,\n",
       "          2.1443e-02, -4.2595e-02, -1.2107e-01,  1.7342e-01,  1.9790e-02],\n",
       "        [-1.0768e-01,  2.5067e-02,  7.2355e-02, -9.1701e-02, -1.5779e-02,\n",
       "          7.7309e-03, -5.4741e-02, -1.0989e-02,  1.9335e-01, -1.0644e-02],\n",
       "        [-8.8708e-02,  3.5900e-02,  1.1445e-01, -2.6537e-02,  1.0048e-02,\n",
       "          3.0952e-02, -1.2803e-01,  1.1070e-01,  1.6460e-01,  6.5641e-03],\n",
       "        [ 2.9944e-02,  2.2898e-02,  1.0624e-01, -9.7947e-02, -1.2310e-02,\n",
       "          8.0222e-02, -2.2633e-02,  8.5317e-03,  1.9810e-01,  5.4351e-02],\n",
       "        [-8.9274e-02,  7.8054e-02,  1.3845e-01, -4.6012e-02,  4.0981e-02,\n",
       "          5.4986e-02, -7.7108e-02, -9.1654e-02,  1.9167e-01,  9.6459e-02],\n",
       "        [-7.4536e-02,  2.3376e-02, -1.4193e-05, -7.7615e-02, -3.2984e-02,\n",
       "          7.3558e-02,  1.9939e-02, -6.3478e-02,  2.8855e-01,  1.3108e-01],\n",
       "        [-8.4220e-02,  1.2036e-01,  7.6075e-02, -4.2848e-02, -8.2680e-02,\n",
       "          1.2632e-02, -3.7244e-02, -3.0082e-03,  1.1982e-01,  4.9766e-02],\n",
       "        [-6.9156e-02,  4.8786e-02,  7.4837e-02, -7.7264e-02, -3.8025e-02,\n",
       "          2.8330e-03, -9.9104e-02, -3.0115e-02,  2.3218e-01,  6.8926e-02],\n",
       "        [-1.2149e-01,  1.0514e-02,  4.6059e-02, -6.8866e-03, -2.6469e-02,\n",
       "         -1.7571e-02, -4.2996e-02,  2.8945e-02,  1.0954e-01,  8.5525e-02],\n",
       "        [-5.0228e-02,  2.5281e-02,  4.0746e-02, -1.2563e-02, -4.4116e-03,\n",
       "          7.6624e-03, -8.8324e-02, -6.6668e-02,  1.5876e-01, -9.5146e-04],\n",
       "        [-9.6746e-02,  2.8411e-02,  9.1027e-02, -8.5349e-02, -2.0423e-02,\n",
       "          5.6128e-02, -3.3040e-02,  2.7520e-02,  2.1578e-01,  3.1995e-02],\n",
       "        [-6.2440e-02,  3.8016e-02,  1.3432e-01, -8.3157e-02,  9.6994e-03,\n",
       "          3.6061e-02, -1.0363e-01, -2.5513e-02,  1.7333e-01,  3.5447e-02],\n",
       "        [-1.0184e-01,  5.5863e-02,  5.2772e-02, -5.0111e-02, -8.1393e-03,\n",
       "          2.8990e-02, -3.9080e-02,  5.0128e-03,  1.6489e-01,  7.0107e-02],\n",
       "        [-7.6033e-02,  1.6581e-02,  3.2764e-02, -9.3959e-02, -1.5597e-02,\n",
       "          5.3165e-02, -4.4474e-02,  6.9656e-02,  8.2444e-02,  3.5526e-02],\n",
       "        [-8.3010e-02,  4.9395e-02, -2.2075e-02, -9.9858e-03,  6.2974e-02,\n",
       "          4.5828e-02, -1.5515e-02,  7.4793e-02,  1.3234e-01,  7.4671e-02],\n",
       "        [ 1.5544e-02,  3.1665e-02,  3.4263e-02, -8.9538e-02, -2.2760e-02,\n",
       "          3.4816e-02, -8.1827e-02, -2.5206e-02,  1.4348e-01,  5.3205e-02],\n",
       "        [-1.2310e-01, -4.0453e-02,  3.8156e-03, -1.3284e-01,  3.9675e-02,\n",
       "          5.1587e-02, -8.4927e-03,  4.4677e-02,  7.9965e-02,  9.0482e-02],\n",
       "        [ 1.1734e-02,  3.2676e-02,  1.6177e-01, -1.0292e-01,  5.2107e-02,\n",
       "         -3.8634e-02,  8.1394e-02, -5.7126e-02,  2.8996e-02, -1.8945e-02],\n",
       "        [-1.0108e-01, -1.7076e-02,  8.9131e-03, -9.5266e-02, -4.6288e-02,\n",
       "          1.0025e-01, -1.0088e-01, -2.6274e-02,  1.7128e-01,  3.4833e-03],\n",
       "        [-7.4466e-03,  3.4876e-02,  6.4409e-02, -1.1531e-02,  2.5335e-02,\n",
       "         -4.3200e-02,  8.2367e-04, -2.7027e-02,  4.7567e-02,  5.5678e-02],\n",
       "        [-9.7496e-02,  1.7921e-02,  1.1030e-01, -6.7558e-02,  1.5942e-02,\n",
       "          1.7601e-02, -1.1272e-02,  4.0841e-02,  1.3414e-01,  8.9562e-02],\n",
       "        [-7.6426e-02,  2.4687e-02,  1.7452e-02, -3.0365e-02, -3.5979e-02,\n",
       "          1.0086e-01, -1.7710e-02,  3.2662e-02,  2.0565e-01,  7.8154e-02],\n",
       "        [-4.6720e-02,  5.5077e-02,  1.3757e-01, -6.3131e-02, -5.8236e-02,\n",
       "          1.0076e-02, -1.1476e-01, -7.1997e-02,  2.4319e-01,  2.0336e-02],\n",
       "        [-3.9954e-02,  7.2331e-02,  5.4394e-02, -2.5594e-02,  9.3209e-03,\n",
       "          1.3182e-02, -1.6753e-03,  5.5891e-02,  7.6885e-02,  7.4393e-02],\n",
       "        [-1.6935e-03,  3.3042e-03,  6.6399e-02, -1.7151e-01, -5.1765e-04,\n",
       "          7.4702e-02,  2.7284e-02, -3.0405e-02,  1.6094e-01,  5.7055e-02],\n",
       "        [-8.4768e-02,  2.4907e-02,  4.4353e-02,  7.5344e-03,  7.4760e-02,\n",
       "          5.1730e-02, -9.5555e-02, -7.5612e-03,  1.7441e-01,  9.1871e-02],\n",
       "        [-8.2111e-02,  4.3971e-02,  1.3229e-01, -7.2972e-02, -4.6739e-04,\n",
       "         -1.0651e-02, -6.0708e-02,  3.2644e-02,  1.0808e-01,  1.5539e-01],\n",
       "        [-2.7548e-02,  5.4289e-02,  1.2750e-01, -6.7748e-02,  2.2369e-02,\n",
       "          1.0690e-01, -5.0209e-03,  3.5233e-02,  1.0600e-01,  4.7347e-02],\n",
       "        [-5.4819e-02, -1.5386e-02,  2.7483e-02, -9.1514e-02, -8.9457e-02,\n",
       "          1.1097e-01, -2.6316e-03, -7.7484e-03,  1.5208e-01,  3.9642e-02],\n",
       "        [-2.3736e-02,  9.1789e-02,  5.3115e-02, -2.1426e-02,  3.0937e-03,\n",
       "          1.7436e-02, -1.1059e-01, -3.8043e-02,  1.1961e-01, -1.6977e-02],\n",
       "        [-8.2847e-02, -2.3812e-02,  5.7712e-02, -1.6709e-01,  4.0192e-02,\n",
       "          3.9988e-02, -8.6417e-02, -4.6402e-03,  1.9785e-01,  1.5539e-01],\n",
       "        [-4.0655e-03,  2.9250e-02,  1.0963e-01, -8.8524e-02, -9.3427e-02,\n",
       "          1.2178e-01,  1.3400e-02, -3.9501e-02,  1.3156e-01,  5.1371e-02],\n",
       "        [ 2.0064e-02,  6.8171e-02,  6.0365e-02, -3.0756e-02, -9.7748e-02,\n",
       "         -5.5481e-02, -1.3750e-01, -9.7006e-02,  1.7052e-01, -3.8801e-02],\n",
       "        [-1.1228e-01,  9.2147e-02,  5.7773e-02, -1.2459e-01,  2.4859e-02,\n",
       "          1.4957e-01,  1.8302e-02,  7.6282e-02,  1.7594e-01,  3.6890e-02],\n",
       "        [-8.1791e-02,  4.8034e-02,  5.7549e-02, -5.5925e-02,  2.5413e-03,\n",
       "          3.6102e-02, -3.1940e-02,  5.9228e-03,  1.6466e-01,  4.1685e-02],\n",
       "        [-7.3456e-02, -1.6303e-02,  5.6180e-02, -1.1013e-01, -7.1187e-02,\n",
       "         -9.1433e-02, -7.8752e-02,  4.1976e-03,  1.2764e-01,  7.8934e-02],\n",
       "        [-4.6367e-02, -6.7063e-02, -1.3706e-02, -3.2461e-02,  1.5367e-02,\n",
       "         -4.6239e-04, -5.3813e-02, -1.4893e-02,  1.5605e-01,  9.5811e-02],\n",
       "        [ 2.1518e-03, -7.9443e-02,  4.2734e-02, -2.0722e-01, -3.4884e-02,\n",
       "          8.2322e-02,  2.1850e-02,  6.1512e-02, -4.8017e-03,  6.6334e-02],\n",
       "        [-1.5285e-02, -8.1526e-02,  5.6731e-02, -6.0626e-02, -5.2933e-02,\n",
       "         -8.5051e-02, -5.4265e-02, -1.1998e-03,  1.5744e-01,  4.4597e-02],\n",
       "        [-8.5285e-02,  7.4500e-02,  3.5656e-02, -8.7149e-02, -8.2915e-02,\n",
       "          4.3787e-02, -6.7392e-02,  1.3491e-02,  1.2647e-01,  9.1264e-02],\n",
       "        [-8.0440e-02,  2.6044e-02,  5.9794e-02, -2.3792e-02, -7.4548e-02,\n",
       "          2.6263e-02, -1.2798e-01,  2.8467e-02,  2.2039e-01,  6.6897e-03],\n",
       "        [-4.6246e-02,  5.4900e-02,  1.2591e-01, -4.2522e-02, -9.2173e-03,\n",
       "          2.0126e-02, -4.6888e-02, -8.6832e-02,  1.6049e-01,  1.2870e-02],\n",
       "        [-1.9896e-02, -6.1376e-02,  4.1546e-02, -7.6234e-02, -8.9606e-02,\n",
       "          2.2882e-02, -7.3577e-02,  3.2167e-02,  1.0357e-01,  1.2548e-01],\n",
       "        [-1.5942e-02,  3.8448e-02,  2.8852e-04, -8.0252e-02,  3.7819e-03,\n",
       "         -8.2478e-03, -2.5392e-03,  3.0129e-02,  1.6661e-01,  1.1890e-02],\n",
       "        [-1.3133e-01,  7.7000e-02,  5.8840e-02, -5.7104e-02, -5.6130e-02,\n",
       "          3.4111e-02, -6.8249e-02,  8.1674e-03,  1.5932e-01,  5.5069e-02],\n",
       "        [-7.5867e-02, -7.7776e-02, -1.4146e-02, -3.8481e-02, -8.3283e-02,\n",
       "          6.0397e-02, -2.0959e-02,  7.2705e-02,  1.9167e-01,  6.6424e-02],\n",
       "        [-4.3269e-03,  5.0083e-02,  5.0071e-02,  1.9753e-02,  1.1993e-03,\n",
       "         -7.0913e-03, -2.4697e-02,  2.4566e-02,  1.6419e-01,  5.1171e-02],\n",
       "        [-7.8690e-02, -4.9591e-02,  2.8171e-02, -1.4126e-01,  7.6939e-03,\n",
       "          2.1894e-02, -6.7663e-03,  6.3816e-02,  1.6896e-01,  1.2608e-01],\n",
       "        [-6.1435e-02,  1.0991e-01,  7.4428e-02, -4.7203e-02,  1.0439e-02,\n",
       "          1.3479e-02, -5.0804e-02, -2.4458e-02,  8.2370e-02, -5.9845e-02],\n",
       "        [-6.7640e-02,  8.3639e-02,  5.5255e-02, -6.9228e-02, -4.0393e-03,\n",
       "          4.6592e-02, -6.8815e-02,  2.7850e-02,  2.1551e-01,  3.2330e-02],\n",
       "        [-4.6614e-02,  4.7447e-02,  1.0778e-01, -1.2551e-01, -3.1114e-02,\n",
       "          6.0565e-02,  5.2519e-02,  9.8425e-02,  1.3468e-02, -7.0614e-03],\n",
       "        [-5.6125e-02,  1.2583e-01,  8.9685e-02, -5.7493e-02,  2.0530e-03,\n",
       "          2.9661e-02, -1.9487e-02,  6.0090e-02,  1.4687e-01,  1.1881e-01],\n",
       "        [-5.0503e-02,  5.0472e-02,  4.6787e-02, -1.7228e-01, -2.9187e-02,\n",
       "          6.8605e-02, -8.0039e-02, -1.1175e-01,  1.4891e-01,  1.0709e-01],\n",
       "        [-3.3304e-02,  7.4394e-02,  2.5652e-02, -8.1594e-02, -7.2982e-02,\n",
       "         -2.0087e-02, -1.3343e-01, -4.4330e-02,  1.7670e-01, -5.6624e-02],\n",
       "        [-5.7209e-03, -1.4973e-02,  1.2936e-01, -1.4773e-01, -1.1475e-03,\n",
       "          4.2155e-02,  1.1679e-02,  1.9656e-02,  1.2889e-01,  6.8863e-02],\n",
       "        [-1.1013e-01,  7.8831e-02,  8.3210e-02, -4.6513e-02,  3.1364e-02,\n",
       "         -1.6252e-03,  2.0207e-02, -7.0829e-03,  1.5257e-01,  1.0071e-01],\n",
       "        [-8.3800e-02, -3.4291e-02,  2.4766e-02, -1.6244e-01, -3.2303e-02,\n",
       "          9.2090e-02,  2.2606e-02,  3.8252e-02,  1.7192e-01,  5.2207e-02],\n",
       "        [-1.5416e-02,  3.4495e-02,  5.5927e-02, -8.3499e-02, -4.5092e-02,\n",
       "         -3.0940e-03, -1.8238e-02, -1.9047e-03,  1.2966e-01,  1.4948e-01],\n",
       "        [-1.3204e-01,  1.1233e-01,  1.1992e-02, -5.6787e-02, -5.2265e-02,\n",
       "          3.3820e-02, -3.7825e-02,  6.7600e-02,  2.6090e-02, -3.4809e-02],\n",
       "        [-6.6153e-02, -4.1182e-02,  2.4181e-02, -8.7529e-02,  4.1233e-02,\n",
       "          3.6314e-02, -2.4663e-02, -4.2497e-02,  2.1243e-01, -1.5490e-03],\n",
       "        [-1.0577e-01,  6.1361e-02,  8.0740e-02, -5.2516e-02,  8.3962e-02,\n",
       "          5.3561e-02, -2.3016e-02, -1.4737e-02,  1.5895e-01,  1.3361e-01],\n",
       "        [-7.0001e-02, -1.2582e-03, -3.0244e-04, -1.4945e-02, -6.0984e-02,\n",
       "          7.0460e-02, -9.9237e-02,  1.0444e-02,  7.8767e-02, -1.0128e-02],\n",
       "        [ 8.4220e-03, -2.7068e-03,  2.4072e-02, -1.0589e-01, -2.1189e-02,\n",
       "          4.9104e-02, -5.9663e-02, -7.1141e-02,  1.1559e-01,  1.0421e-02],\n",
       "        [-7.1812e-02,  4.9713e-02,  5.0129e-02, -1.2447e-01,  2.3147e-02,\n",
       "          5.0678e-02, -8.4937e-02, -5.1120e-02,  1.7012e-01,  1.1396e-01],\n",
       "        [-7.5642e-02,  2.1197e-02, -1.3357e-02, -9.3196e-02, -4.6427e-02,\n",
       "          2.1008e-02,  1.6463e-02,  2.8031e-02,  7.6574e-02,  9.1561e-02],\n",
       "        [-9.4267e-02,  2.3811e-02, -6.3546e-03, -1.6884e-01,  5.1813e-02,\n",
       "          1.8672e-02,  5.9353e-02,  3.4167e-02,  1.6209e-01,  2.4616e-02],\n",
       "        [ 1.5981e-03,  9.2897e-02,  6.1134e-02, -1.6332e-01, -7.0330e-02,\n",
       "          6.6153e-02,  3.7697e-02,  6.7484e-02,  1.6247e-01,  4.5784e-02],\n",
       "        [-2.3169e-02,  1.3563e-02,  8.5317e-02,  5.7581e-02,  6.1692e-03,\n",
       "          5.5045e-03, -9.8636e-02, -8.0377e-02,  1.6593e-01,  4.0570e-02],\n",
       "        [-3.9060e-02,  8.4243e-02,  5.1634e-02, -4.8696e-02, -2.2972e-02,\n",
       "          4.1327e-02,  1.1259e-02,  1.5167e-02,  8.6950e-02,  2.3191e-02],\n",
       "        [-1.1806e-02,  4.0069e-03,  7.3803e-02, -2.3390e-02, -5.5038e-02,\n",
       "          9.8532e-03, -6.1204e-02, -3.7511e-02,  2.6592e-01,  6.3250e-02],\n",
       "        [-1.1316e-01,  7.1679e-02,  9.8906e-03, -6.9264e-02, -8.5974e-04,\n",
       "          4.3922e-02, -7.4181e-02,  2.6872e-02,  1.6249e-01,  1.0793e-01],\n",
       "        [-1.3057e-01,  1.4471e-02,  1.0994e-01, -1.5204e-01, -3.0163e-02,\n",
       "          4.8104e-02, -8.6383e-02, -5.2678e-02,  2.2984e-01,  6.3295e-02],\n",
       "        [-1.4397e-01, -9.9952e-03, -4.2299e-02, -2.0473e-01,  1.5423e-02,\n",
       "          2.3738e-02, -1.4271e-02,  2.7927e-02,  9.5481e-02,  4.1312e-02],\n",
       "        [-2.6959e-02, -4.1028e-03,  4.0624e-02, -3.8677e-02,  2.7847e-02,\n",
       "          1.8215e-02, -3.9063e-02, -5.4566e-02,  8.2674e-02,  3.4432e-02],\n",
       "        [-1.4098e-01,  1.5195e-02,  7.5774e-02, -7.6238e-02,  8.7858e-02,\n",
       "          5.2231e-02, -2.6089e-02, -2.2110e-02,  1.6613e-01,  1.7952e-01],\n",
       "        [-3.9873e-02,  1.3481e-02,  6.5999e-02,  2.6709e-02, -2.4850e-02,\n",
       "          8.8858e-03, -2.9423e-02, -3.1287e-02,  1.6768e-01,  4.5984e-02],\n",
       "        [-5.2614e-03, -3.2834e-04, -4.3499e-02, -1.6147e-01,  5.6682e-02,\n",
       "         -1.8399e-02,  2.8922e-02, -6.4545e-04,  9.6281e-02,  8.7529e-02],\n",
       "        [-3.4989e-02, -1.3531e-03,  5.5262e-02, -1.0432e-01,  2.1848e-02,\n",
       "         -1.1604e-01, -9.6925e-02,  1.0143e-01,  1.6744e-01,  5.2979e-02],\n",
       "        [-2.6664e-02, -4.4243e-02,  4.8616e-02, -5.5849e-02,  3.7558e-02,\n",
       "          2.1734e-02, -5.9032e-02, -7.1702e-03,  1.5089e-01,  1.1946e-02],\n",
       "        [-1.0794e-01, -2.0360e-02,  3.9854e-02, -1.0125e-01, -1.4731e-01,\n",
       "          2.6829e-03,  4.2271e-02,  1.7781e-02,  1.1674e-01, -4.1125e-02],\n",
       "        [-6.6600e-02,  2.2454e-02,  2.0490e-02, -1.5031e-01, -3.3961e-02,\n",
       "          4.6151e-02,  2.7927e-02,  4.5408e-02,  1.2897e-01,  7.5870e-02],\n",
       "        [-1.2324e-01, -1.8614e-02,  3.5863e-02, -7.7963e-02,  7.4385e-02,\n",
       "         -3.2892e-02, -1.4140e-04,  9.3100e-02,  1.1660e-01,  1.3549e-01],\n",
       "        [-5.3399e-02,  3.1857e-02,  3.6035e-02, -1.0450e-01, -4.9228e-03,\n",
       "          1.2322e-01,  4.2964e-03,  5.4826e-02,  2.1359e-01,  4.1470e-02],\n",
       "        [-1.7705e-01,  3.6715e-02, -3.7586e-02, -2.3523e-02,  2.1263e-02,\n",
       "          8.2187e-03, -6.7356e-02, -3.7510e-02,  2.2484e-01,  4.6099e-02],\n",
       "        [-7.1830e-02,  1.0371e-01,  8.8895e-02, -6.9546e-02,  8.2861e-02,\n",
       "          1.9115e-02, -6.9947e-02,  5.0231e-02,  1.3818e-01,  6.9358e-02],\n",
       "        [-1.5979e-01, -1.0255e-02,  1.3480e-01, -2.9462e-02,  6.3418e-02,\n",
       "          7.4208e-02, -1.4536e-01,  4.2790e-04,  1.7300e-01,  1.7124e-02],\n",
       "        [-9.1419e-02, -2.5097e-02,  7.0674e-02, -5.7382e-02, -7.5507e-02,\n",
       "          2.6246e-02, -1.3559e-01, -1.2359e-02,  1.8757e-01,  5.6482e-02],\n",
       "        [-6.1603e-02,  3.5216e-03,  8.5023e-02, -3.2386e-02, -1.4263e-02,\n",
       "          7.2658e-02, -2.8486e-02,  6.6108e-03,  2.5843e-01,  9.3158e-02],\n",
       "        [-5.6715e-02,  4.2392e-02,  8.5040e-02, -7.0064e-02, -4.0556e-03,\n",
       "          1.2748e-03, -1.1152e-01,  1.8276e-02,  2.4062e-01,  1.1878e-01],\n",
       "        [-1.4522e-02,  6.7110e-02,  1.9877e-02,  1.1286e-02, -5.8362e-02,\n",
       "         -7.4848e-03, -1.4013e-01, -5.5054e-02,  2.5908e-01,  9.6872e-02],\n",
       "        [-1.0234e-01,  3.7850e-02,  8.5547e-02, -6.9181e-02,  7.9405e-03,\n",
       "          5.0947e-02,  4.9848e-02, -3.3711e-02, -5.0897e-02,  1.0775e-02],\n",
       "        [ 1.4703e-02, -2.8257e-03,  1.6260e-01, -6.2514e-02,  2.6382e-02,\n",
       "          2.0271e-02, -1.1626e-02,  1.1788e-01,  1.1276e-01,  6.1153e-02],\n",
       "        [-7.5009e-02, -2.0235e-02, -2.0624e-02, -1.4138e-01, -3.5117e-03,\n",
       "         -3.0798e-03, -5.1756e-02,  9.4873e-02,  1.8041e-01,  2.7795e-02],\n",
       "        [-1.2308e-01, -1.2713e-02,  5.4755e-02, -6.0498e-02, -2.8121e-02,\n",
       "          3.5272e-02, -6.3832e-03,  2.3243e-03,  2.2436e-01,  4.5150e-02],\n",
       "        [ 8.3787e-03,  2.0248e-02,  3.5773e-02, -6.3907e-02,  6.7234e-02,\n",
       "          8.6769e-02, -4.4328e-02,  1.4881e-02,  1.4677e-01,  4.6332e-02]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of dimension: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/ssd_data/Son/LRBA/debug.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Binstagram/ssd_data/Son/LRBA/debug.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m loss_fn(data, target)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torch/nn/functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of dimension: 1"
     ]
    }
   ],
   "source": [
    "loss_fn(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack_models.autoencoders import MNISTAutoencoder as Autoencoder\n",
    "import torch\n",
    "\n",
    "atkmodel = Autoencoder().to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atkmodel.load_state_dict(torch.load(\"./checkpoint/lira/lira_mnist_lenet_autoencoder_0.03.pt\", map_location=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming you have the data and target tensors\n",
    "data = torch.randn(64, 3, 32, 32)  # Replace this with your actual data\n",
    "# target = torch.randint(0, 10, (64,))  # Replace this with your actual target tensor\n",
    "target = torch.tensor([1,2,3,4])  # Replace this with your actual target tensor\n",
    "\n",
    "# Get indices where target is equal to 1\n",
    "indices = (target == 5).nonzero(as_tuple=True)[0]\n",
    "\n",
    "# Use the indices to select data with target==1\n",
    "selected_data = data[indices]\n",
    "\n",
    "# Print the shape of the selected data\n",
    "print(selected_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aksdjhaksdh\n"
     ]
    }
   ],
   "source": [
    "if len(indices) == 0:\n",
    "    print('aksdjhaksdh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a[[False, False, False]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(250.0500, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Create a tensor of size (4, 3, 32, 32)\n",
    "a = torch.arange(10, dtype=torch.float32, requires_grad=True) # a is a batch of 4 images size 32x32 with 3 channels\n",
    "\n",
    "# Create another tensor of size (4, 3, 32, 32)\n",
    "b = torch.arange(10, 20, dtype=torch.float32, requires_grad=True) # b is a batch of 4 images size 32x32 with 3 channels\n",
    "\n",
    "c = torch.tensor(-11, dtype=torch.float32, requires_grad=True)\n",
    "c = max(torch.tensor(0.05, requires_grad=False), c)\n",
    "\n",
    "optimizer = torch.optim.Adam([a, b, c], lr=0.001)\n",
    "# Compute the L2 distance of a and b and then sum all 4 images\n",
    "loss = torch.sum(torch.square(a - b)) / 4 + c\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0500)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0500)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.tensor(-11, dtype=torch.float32, requires_grad=True)\n",
    "c = max(0.05, c)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a list of tensors\n",
    "\n",
    "a = torch.randint(-4, 4, (2, 3))\n",
    "b = torch.randint(-4, 4, (2, 3))\n",
    "c = torch.randint(-4, 4, (2, 3))\n",
    "d = torch.randint(-4, 4, (2, 3))\n",
    "e = torch.randint(-4, 4, (2, 3))\n",
    "f = torch.randint(-4, 4, (2, 3))\n",
    "\n",
    "ratio = 0.5\n",
    "grad_list = []\n",
    "grad_abs_sum_list = []\n",
    "# Print the result\n",
    "a.shape, b.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 2, 4, 4, 1, 2]),\n",
       " tensor([0, 3, 2, 4, 2, 2]),\n",
       " tensor([4, 2, 3, 3, 0, 2]),\n",
       " tensor([1, 0, 1, 4, 1, 0]),\n",
       " tensor([0, 2, 3, 3, 3, 1]),\n",
       " tensor([1, 2, 2, 3, 3, 1])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_list.append(a.abs().view(-1))\n",
    "grad_list.append(b.abs().view(-1))\n",
    "grad_list.append(c.abs().view(-1))\n",
    "grad_list.append(d.abs().view(-1))\n",
    "grad_list.append(e.abs().view(-1))\n",
    "grad_list.append(f.abs().view(-1))\n",
    "grad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 13, 14, 7, 12, 12]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_abs_sum_list.append(a.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list.append(b.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list.append(c.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list.append(d.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list.append(e.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list.append(f.abs().view(-1).sum().item())\n",
    "grad_abs_sum_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 4, 4, 1, 2, 0, 3, 2, 4, 2, 2, 4, 2, 3, 3, 0, 2, 1, 0, 1, 4, 1, 0,\n",
       "        0, 2, 3, 3, 3, 1, 1, 2, 2, 3, 3, 1])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_list = torch.cat(grad_list)\n",
    "grad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 16, 19, 23, 24, 20, 35,  0, 30, 22])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, indices = torch.topk(-1*grad_list, 10)\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_flat_all_layer = torch.zeros(len(grad_list))\n",
    "mask_flat_all_layer[indices] = 1.0\n",
    "mask_flat_all_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1]),\n",
       "indices=tensor([21, 28,  9, 31,  5, 34,  1,  2, 33, 24]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(-1*grad_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_length = len(a.abs().view(-1))\n",
    "gradients_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_mask_list = []\n",
    "grad_abs_percentage_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "b = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "c = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "d = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "e = torch.tensor([1,2,3,4], dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 2., 3., 4.]),\n",
       " tensor([1., 2., 3., 4.]),\n",
       " tensor([1., 2., 3., 4.]),\n",
       " tensor([1., 2., 3., 4.]),\n",
       " tensor([1., 2., 3., 4.])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "t.append(a)\n",
    "t.append(b)\n",
    "t.append(c)\n",
    "t.append(d)\n",
    "t.append(e)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(t) / len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3,4], dtype=torch.float32, requires_grad=True, device='cuda')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.], device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "t.append(a)\n",
    "t.append(a)\n",
    "sum(t) / len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 1., 2., 3., 4.], device='cuda:0',\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139785753930352"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139785751993280"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11]],\n",
       " \n",
       "         [[12, 13, 14, 15],\n",
       "          [16, 17, 18, 19],\n",
       "          [20, 21, 22, 23]]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "a = torch.tensor(range(24)).view(2, 3, 4)\n",
    "b = torch.tensor(range(24)).view(2, 3, 4)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.square(a-b), dim=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary PyTorch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import kornia.augmentation as A\n",
    "\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from utils.backdoor import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_MIN, IMAGENET_MAX\n",
    "from attack_models.autoencoders import ConditionalAutoencoder\n",
    "from models.resnet_cifar import ResNet18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgtmodel = ConditionalAutoencoder(n_classes=10, input_dim=32).to(\"cuda\")\n",
    "model = ResNet18().to(\"cuda\")\n",
    "\n",
    "prefix = f\"/hdd/home/ssd_data/Son/LRBA/saved_models/model_CIFAR10_01.21_16.12.04_cifar10/\"\n",
    "path = prefix + \"model_last.pt.tar\"\n",
    "with open(path, \"rb\") as f:\n",
    "    checkpoint = torch.load(f, map_location=\"cuda\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    tgtmodel.load_state_dict(checkpoint[\"tgt_state_dict\"])\n",
    "\n",
    "tgtoptimizer = torch.optim.Adam(tgtmodel.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbTransform(torch.nn.Module):\n",
    "    def __init__(self, f, p=1):\n",
    "        super(ProbTransform, self).__init__()\n",
    "        self.f = f\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):  # , **kwargs):\n",
    "        if random.random() < self.p:\n",
    "            return self.f(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class PostTensorTransform(torch.nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(PostTensorTransform, self).__init__()\n",
    "        self.random_crop = ProbTransform(\n",
    "            A.RandomCrop((32, 32), padding=5), p=0.8\n",
    "        )\n",
    "        self.random_rotation = ProbTransform(A.RandomRotation(10), p=0.5)\n",
    "        if opt.dataset == \"cifar10\":\n",
    "            self.random_horizontal_flip = A.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for module in self.children():\n",
    "            x = module(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:1282\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:1328\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1327\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1328\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:1277\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1277\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1037\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1040\u001b[0m \n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:975\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/http/client.py:1454\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     server_hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m-> 1454\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/ssl.py:513\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    508\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    509\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    510\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/ssl.py:1071\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1071\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m transform_train \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(), normalize,])\n\u001b[1;32m      5\u001b[0m transform_test \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([transforms\u001b[38;5;241m.\u001b[39mToTensor(), normalize])\n\u001b[0;32m----> 7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset,\n\u001b[1;32m     14\u001b[0m                                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     15\u001b[0m                                     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m                                     num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(\n\u001b[1;32m     18\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m     transform\u001b[38;5;241m=\u001b[39mtransform_test)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torchvision/datasets/cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torchvision/datasets/cifar.py:139\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torchvision/datasets/utils.py:434\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[1;32m    432\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[0;32m--> 434\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torchvision/datasets/utils.py:134\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    131\u001b[0m     _download_file_from_remote_location(fpath, url)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# expand redirect chain if needed\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43m_get_redirect_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_redirect_hops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# check if file is located on Google Drive\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     file_id \u001b[38;5;241m=\u001b[39m _get_google_drive_file_id(url)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/torchvision/datasets/utils.py:82\u001b[0m, in \u001b[0;36m_get_redirect_url\u001b[0;34m(url, max_hops)\u001b[0m\n\u001b[1;32m     79\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT}\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_hops \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m==\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-gpu/lib/python3.10/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:997)>"
     ]
    }
   ],
   "source": [
    "PostTensorTransform(hlpr.params).to(hlpr.params.device)\n",
    "\n",
    "post_transforms = PostTensorTransform(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
    "\n",
    "normalize = transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD)\n",
    "\n",
    "transform_train = transforms.Compose([transforms.ToTensor(), normalize,])\n",
    "        \n",
    "transform_test = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "                        root=\"./data\",\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                        batch_size=64,\n",
    "                        shuffle=True,\n",
    "                        num_workers=0)\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "                        root=\"./data\",\n",
    "                        train=False,\n",
    "                        download=True,\n",
    "                        transform=transform_test)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                        batch_size=512,\n",
    "                        shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "clip_image = lambda x: torch.clamp(x, IMAGENET_MIN, IMAGENET_MAX)\n",
    "target_transform = lambda x: torch.ones_like(x) * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_atkdata = post_transforms(atkdata)\n",
    "augmented_data = post_transforms(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
