task: MNISTMarksman
synthesizer: Pattern


batch_size: 64
test_batch_size: 100
lr: 0.005
momentum: 0.9
decay: 0.0005
epochs: 1500
poison_epoch: 1
poison_epoch_stop: 1500
save_on_epochs: # [10, 20, 30, 40, 50]
optimizer: SGD
log_interval: 100
device: cuda

poisoning_proportion: 1.0
backdoor_label: 8

resume_model: # resume_model_mnist/model_epoch_10.pt.tar

save_model: False
log: True
report_train_loss: False

transform_train: True

fl: True
fl_no_models: 10
fl_local_epochs: 1
fl_poison_epochs: 5
fl_total_participants: 100
fl_eta: 1
fl_sample_dirichlet: True
fl_dirichlet_alpha: 0.5

fl_number_of_adversaries: 4
fl_weight_scale: 5
fl_adv_group_size: 2
# fl_single_epoch_attack: 20

attack: Marksman # Marksman
defense: FedAvg # FLAME, Deepsight, Foolsgold, FLDetector, RFLBAT, FedAvg
fl_num_neurons: 8
noise_mask_alpha: 0 # 0.5
lagrange_step: 0.1

# Marksman Settings
clsmodel: mnist_cnn
lr_atk: 0.0001
eps: 0.3 # epsilon for data poisoning
target_label: [8,8,8,8]
num_classes: 10
attack_portion: 1.0
alpha: 0.5
test_n_size: 10
input_height: 32
input_width: 32
input_channel: 1
random_rotation: 10
random_crop: 5
dataset: mnist
mode: all2one
fixed_frequency: 1
normal_training: False # False means only training benign clients, True means training malicious (if any) and benign clients
only_target_examples: False # False means get randomly examples from the original dataset, True means get only the target examples
multiplier: 1
